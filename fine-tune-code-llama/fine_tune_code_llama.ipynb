{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Crossme0809/frenzyTechAI/blob/main/fine-tune-code-llama/fine_tune_code_llama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5rfduRD1CSF"
   },
   "source": [
    "# Code Llama 微调指南\n",
    "\n",
    "**在本指南中，我将向您展示如何微调 Code Llama，使其成为 SQL 开发人员的野兽。对于编码任务，您通常可以从 Code Llama 获得比 Llama 2 更好的性能，特别是当您将模型专门用于特定任务时：**\n",
    "\n",
    "- 使用 [b-mc2/sql-create-context](https://huggingface.co/datasets/b-mc2/sql-create-context) 这是一堆文本查询及其相应的 SQL 查询\n",
    "- Lora 方法，将基本模型量化为 int 8，冻结其权重，仅训练适配器\n",
    "- 大部分代码是从 [alpaca-lora](https://github.com/tloen/alpaca-lora) 参考的，同时也进行了一定的改进与优化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFQ9XeBI1CSG"
   },
   "source": [
    "### 2. Pip installs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Y0x4OWfq1CSG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://bytedpypi.byted.org/simple\n",
      "Collecting git+https://github.com/huggingface/transformers.git@main\n",
      "  Cloning https://github.com/huggingface/transformers.git (to revision main) to /tmp/pip-req-build-7v9zqvxo\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-7v9zqvxo\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit c8c8dffbe45ebef0a8dba4a51024e5e5e498596b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bitsandbytes in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (0.45.0)\n",
      "Requirement already satisfied: accelerate in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (0.26.0)\n",
      "Requirement already satisfied: filelock in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers==4.48.0.dev0) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers==4.48.0.dev0) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers==4.48.0.dev0) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers==4.48.0.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers==4.48.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers==4.48.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers==4.48.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers==4.48.0.dev0) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers==4.48.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers==4.48.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: torch in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from bitsandbytes) (2.5.1)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: psutil in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (2023.9.2)\n",
      "Requirement already satisfied: networkx in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests->transformers==4.48.0.dev0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests->transformers==4.48.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests->transformers==4.48.0.dev0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests->transformers==4.48.0.dev0) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://bytedpypi.byted.org/simple\n",
      "Collecting git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08\n",
      "  Cloning https://github.com/huggingface/peft.git (to revision e536616888d51b453ed354a6f1e243fecb02ea08) to /tmp/pip-req-build-t02nir6n\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-t02nir6n\n",
      "  Running command git rev-parse -q --verify 'sha^e536616888d51b453ed354a6f1e243fecb02ea08'\n",
      "  Running command git fetch -q https://github.com/huggingface/peft.git e536616888d51b453ed354a6f1e243fecb02ea08\n",
      "  Running command git checkout -q e536616888d51b453ed354a6f1e243fecb02ea08\n",
      "  Resolved https://github.com/huggingface/peft.git to commit e536616888d51b453ed354a6f1e243fecb02ea08\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from peft==0.3.0.dev0) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from peft==0.3.0.dev0) (24.2)\n",
      "Requirement already satisfied: psutil in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from peft==0.3.0.dev0) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from peft==0.3.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from peft==0.3.0.dev0) (2.5.1)\n",
      "Requirement already satisfied: transformers in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from peft==0.3.0.dev0) (4.48.0.dev0)\n",
      "Requirement already satisfied: accelerate in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from peft==0.3.0.dev0) (0.26.0)\n",
      "Requirement already satisfied: filelock in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.3.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from accelerate->peft==0.3.0.dev0) (0.26.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from accelerate->peft==0.3.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers->peft==0.3.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers->peft==0.3.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers->peft==0.3.0.dev0) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from transformers->peft==0.3.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.3.0.dev0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests->transformers->peft==0.3.0.dev0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests->transformers->peft==0.3.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests->transformers->peft==0.3.0.dev0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests->transformers->peft==0.3.0.dev0) (2024.8.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://bytedpypi.byted.org/simple\n",
      "Requirement already satisfied: datasets==2.10.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (0.3.6)\n",
      "Requirement already satisfied: pandas in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets==2.10.1) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (3.11.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (0.26.3)\n",
      "Requirement already satisfied: packaging in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (24.2)\n",
      "Requirement already satisfied: responses<0.19 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from datasets==2.10.1) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.18.3)\n",
      "Requirement already satisfied: filelock in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from pandas->datasets==2.10.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from pandas->datasets==2.10.1) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from pandas->datasets==2.10.1) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.10.1) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://bytedpypi.byted.org/simple\n",
      "Requirement already satisfied: wandb in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (0.19.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (5.29.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (6.1.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (2.10.3)\n",
      "Requirement already satisfied: pyyaml in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (2.19.2)\n",
      "Requirement already satisfied: setproctitle in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /mnt/bd/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git@main bitsandbytes accelerate  # we need latest transformers for this\n",
    "!pip install git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08\n",
    "!pip install datasets==2.10.1\n",
    "import locale # colab workaround\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\" # colab workaround\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCmGzYg51CSH"
   },
   "source": [
    "我使用了一台配置了 Python 3.10 和 Cuda 11.8 的 A100 GPU 服务器来运行本文中的代码。大约运行了一个小时。(为了验证可移植性，我还试验在Colab上运行代码，效果都很好。)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mu9JczX1CSH"
   },
   "source": [
    "### 加载库\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oTeYW8z51CSH"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32zH9-hM1CSH"
   },
   "source": [
    "（如果出现导入​​错误，请尝试重新启动 Jupyter 内核）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4M9KyT0S1CSH"
   },
   "source": [
    "### 加载数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answer'],\n",
       "    num_rows: 78577\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "w44O1EK-1CSH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/root/.cache/huggingface/datasets/json/default-93e9303f560821d1/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answer'],\n",
       "    num_rows: 78577\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# dataset = load_dataset(\"/workspace/llm/tester-volume/llm_model/datasets\", split=\"train\")\n",
    "dataset = load_dataset('json', split='train', data_files='/workspace/llm/tester-volume/llm_model/datasets/sql-create-context-v4.json')\n",
    "train_dataset = dataset.train_test_split(test_size=0.1)[\"train\"]\n",
    "eval_dataset = dataset.train_test_split(test_size=0.1)[\"test\"]\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJ54EffO1CSI"
   },
   "source": [
    "上面从 Huggingface Hub 中提取数据集，并将其中的 10% 分成评估集，以检查模型在训练中的表现如何。如果您想加载自己的数据集，请执行以下操作：\n",
    "\n",
    "```\n",
    "train_dataset = load_dataset('json', data_files='train_set.jsonl', split='train')\n",
    "eval_dataset = load_dataset('json', data_files='validation_set.jsonl', split='train')\n",
    "```\n",
    "\n",
    "如果您想查看数据集中的任何样本，只需执行以下操作：``` ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fFbeaZzf1CSJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the denomination for the stamp issued 8 January 2009?', 'context': 'CREATE TABLE table_name_34 (denomination VARCHAR, date_of_issue VARCHAR)', 'answer': 'SELECT denomination FROM table_name_34 WHERE date_of_issue = \"8 january 2009\"'}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHdMYcu61CSJ"
   },
   "source": [
    "每个条目由文本“问题”、sql 表“上下文”和“答案”组成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ig7NvWN1CSJ"
   },
   "source": [
    "### 加载模型\n",
    "我从 Huggingface 中以 int8 加载代码 llama。Lora的标准："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rMnU93bY1CSJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>base_model = <span style=\"color: #808000; text-decoration-color: #808000\">\"/workspace/llm/tester-volume/llm_model/AI-ModelScope/CodeLlama-7b-hf\"</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 2 model = AutoModelForCausalLM.from_pretrained(                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>base_model,                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>load_in_4bit=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>torch_dtype=torch.float16,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/workspace/llm/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages/transfor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">auto_factory.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">564</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">561 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">562 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(config) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._model_mapping.keys():                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">563 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>model_class = _get_model_class(config, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._model_mapping)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>564 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> model_class.from_pretrained(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">565 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">566 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">567 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/workspace/llm/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages/transfor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3669</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3666 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>hf_quantizer = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3667 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3668 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> hf_quantizer <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3669 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>hf_quantizer.validate_environment(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3670 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>torch_dtype=torch_dtype,                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3671 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>from_tf=from_tf,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3672 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>from_flax=from_flax,                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/workspace/llm/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages/transfor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">mers/quantizers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">quantizer_bnb_4bit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">70</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">validate_environment</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 67 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 68 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">validate_environment</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs):                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> is_accelerate_available():                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 70 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ImportError</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 71 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Using `bitsandbytes` 4-bit quantization requires Accelerate: `pip inst</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 72 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> is_bitsandbytes_available():                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ImportError: </span>Using `bitsandbytes` <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-bit quantization requires Accelerate: `pip install <span style=\"color: #008000; text-decoration-color: #008000\">'accelerate&gt;=0.26.0'</span>`\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0mbase_model = \u001b[33m\"\u001b[0m\u001b[33m/workspace/llm/tester-volume/llm_model/AI-ModelScope/CodeLlama-7b-hf\u001b[0m\u001b[33m\"\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 2 model = AutoModelForCausalLM.from_pretrained(                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   \u001b[0mbase_model,                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   \u001b[0mload_in_4bit=\u001b[94mTrue\u001b[0m,                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   \u001b[0mtorch_dtype=torch.float16,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/workspace/llm/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages/transfor\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mmers/models/auto/\u001b[0m\u001b[1;33mauto_factory.py\u001b[0m:\u001b[94m564\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m561 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m562 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mtype\u001b[0m(config) \u001b[95min\u001b[0m \u001b[96mcls\u001b[0m._model_mapping.keys():                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m563 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_class = _get_model_class(config, \u001b[96mcls\u001b[0m._model_mapping)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m564 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m model_class.from_pretrained(                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m565 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m566 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m567 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/workspace/llm/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages/transfor\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mmers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m3669\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3666 \u001b[0m\u001b[2m│   │   │   \u001b[0mhf_quantizer = \u001b[94mNone\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3667 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3668 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m hf_quantizer \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3669 \u001b[2m│   │   │   \u001b[0mhf_quantizer.validate_environment(                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3670 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtorch_dtype=torch_dtype,                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3671 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfrom_tf=from_tf,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3672 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfrom_flax=from_flax,                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/workspace/llm/tester-volume/software/conda1/envs/pretrain/lib/python3.10/site-packages/transfor\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mmers/quantizers/\u001b[0m\u001b[1;33mquantizer_bnb_4bit.py\u001b[0m:\u001b[94m70\u001b[0m in \u001b[92mvalidate_environment\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 67 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 68 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mvalidate_environment\u001b[0m(\u001b[96mself\u001b[0m, *args, **kwargs):                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 69 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m is_accelerate_available():                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 70 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mImportError\u001b[0m(                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 71 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mUsing `bitsandbytes` 4-bit quantization requires Accelerate: `pip inst\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 72 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m is_bitsandbytes_available():                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mImportError: \u001b[0mUsing `bitsandbytes` \u001b[1;36m4\u001b[0m-bit quantization requires Accelerate: `pip install \u001b[32m'accelerate>=0.26.0'\u001b[0m`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = \"/workspace/llm/tester-volume/llm_model/AI-ModelScope/CodeLlama-7b-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    # device_map=\"auto\",\n",
    "    # low_cpu_mem_usage=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3OF-wtj1CSJ"
   },
   "source": [
    "torch_dtype=torch.float16 表示使用 float16 表示形式执行计算，即使值本身是 8 位整数。\n",
    "\n",
    "如果出现错误“ValueError：Tokenizer 类 CodeLlamaTokenizer 不存在或当前未导入。”确保您的 Transformer 版本为 4.33.0.dev0 并且加速 >=0.20.3。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2VXqJJe1CSJ"
   },
   "source": [
    "### 3. 检查基础型号\n",
    "一个非常好的常见做法是检查模型是否已经可以完成手头的任务。微调是您要不惜一切代价尽量避免的事情：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiyAff1a1CSJ"
   },
   "outputs": [],
   "source": [
    "eval_prompt = \"\"\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
    "\n",
    "You must output the SQL query that answers the question.\n",
    "### Input:\n",
    "Which Class has a Frequency MHz larger than 91.5, and a City of license of hyannis, nebraska?\n",
    "\n",
    "### Context:\n",
    "CREATE TABLE table_name_12 (class VARCHAR, frequency_mhz VARCHAR, city_of_license VARCHAR)\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "# {'question': 'Name the comptroller for office of prohibition', 'context': 'CREATE TABLE table_22607062_1 (comptroller VARCHAR, ticket___office VARCHAR)', 'answer': 'SELECT comptroller FROM table_22607062_1 WHERE ticket___office = \"Prohibition\"'}\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "544rmsdU1CSJ"
   },
   "source": [
    "输出结果：\n",
    "```\n",
    "SELECT * FROM table_name_12 WHERE class > 91.5 AND city_of_license = 'hyannis, nebraska'\n",
    "```\n",
    "如果输入只要求上课，这显然是错误的！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puuOXL2R1CSJ"
   },
   "source": [
    "### 4. Tokenization\n",
    "设置一些标记化设置，例如左填充，因为它使[训练使用更少的内存](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1P0mphA1CSJ"
   },
   "outputs": [],
   "source": [
    "tokenizer.add_eos_token = True\n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpo66hMo1CSJ"
   },
   "source": [
    "设置 tokenize 函数以使 labels 和 input_ids 相同。这基本上就是[自我监督微调](https://neptune.ai/blog/self-supervised-learning)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjSerml71CSJ"
   },
   "outputs": [],
   "source": [
    "def tokenize(prompt):\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "\n",
    "    # \"self-supervised learning\" means the labels are also the inputs:\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNk_3THv1CSK"
   },
   "source": [
    "并运行将每个 data_point 转换为我在网上找到的效果很好的提示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvO7A-ZF1CSK"
   },
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt =f\"\"\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
    "\n",
    "You must output the SQL query that answers the question.\n",
    "\n",
    "### Input:\n",
    "{data_point[\"question\"]}\n",
    "\n",
    "### Context:\n",
    "{data_point[\"context\"]}\n",
    "\n",
    "### Response:\n",
    "{data_point[\"answer\"]}\n",
    "\"\"\"\n",
    "    return tokenize(full_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLvwo-ax1CSK"
   },
   "source": [
    "重新格式化以提示并标记每个样本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SA2BqSzW1CSK"
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5ByhitV1CSK"
   },
   "source": [
    "### 5. 设置 Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9q_26pz71CSK"
   },
   "outputs": [],
   "source": [
    "model.train() # put model back into training mode\n",
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "    \"q_proj\",\n",
    "    \"k_proj\",\n",
    "    \"v_proj\",\n",
    "    \"o_proj\",\n",
    "],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvkQ3igC1CSK"
   },
   "source": [
    "要从检查点恢复，请将resume_from_checkpoint 设置为要从中恢复的adapter_model.bin 的路径。此代码将替换连接到模型的 lora 适配器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMTxR2JT1CSK"
   },
   "outputs": [],
   "source": [
    "resume_from_checkpoint = \"\" # set this to the adapter_model.bin file you want to resume from\n",
    "\n",
    "if resume_from_checkpoint:\n",
    "    if os.path.exists(resume_from_checkpoint):\n",
    "        print(f\"Restarting from {resume_from_checkpoint}\")\n",
    "        adapters_weights = torch.load(resume_from_checkpoint)\n",
    "        set_peft_model_state_dict(model, adapters_weights)\n",
    "    else:\n",
    "        print(f\"Checkpoint {resume_from_checkpoint} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW1wtvbP1CSK"
   },
   "source": [
    "设置权重和偏差以查看训练图的可选内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AC1_qWbS1CSK"
   },
   "outputs": [],
   "source": [
    "wandb_project = \"sql-try2-coder\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iv4txxu1CSK"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYSsnciQ1CSK"
   },
   "source": [
    "### 6. 训练参数\n",
    "如果 GPU 内存不足，请更改 per_device_train_batch_size。 gradient_accumulation_steps 变量应确保这不会影响训练运行期间的批量动态。所有其他变量都是标准的东西，我不建议乱搞："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvEi1kP21CSK"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "per_device_train_batch_size = 32\n",
    "gradient_accumulation_steps = batch_size // per_device_train_batch_size\n",
    "output_dir = \"sql-code-llama\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        warmup_steps=100,\n",
    "        max_steps=400,\n",
    "        learning_rate=3e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_torch\",\n",
    "        evaluation_strategy=\"steps\", # if val_set_size > 0 else \"no\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=20,\n",
    "        save_steps=20,\n",
    "        output_dir=output_dir,\n",
    "        # save_total_limit=3,\n",
    "        load_best_model_at_end=False,\n",
    "        # ddp_find_unused_parameters=False if ddp else None,\n",
    "        group_by_length=True, # group sequences of roughly the same length together to speed up training\n",
    "        report_to=\"wandb\", # if use_wandb else \"none\",\n",
    "        run_name=f\"codellama-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\", # if use_wandb else None,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorForSeq2Seq(\n",
    "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aJp6Jxl1CSK"
   },
   "source": [
    "然后我们进行一些与 pytorch 相关的优化，这只是使训练更快，但不影响准确性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ycCHZZl1CSK"
   },
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "\n",
    "old_state_dict = model.state_dict\n",
    "model.state_dict = (lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())).__get__(\n",
    "    model, type(model)\n",
    ")\n",
    "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "    print(\"compiling the model\")\n",
    "    model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bF5oWKxK1CSL"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1dRQLMT1CSU"
   },
   "source": [
    "### 加载最终检查点\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRdVgDTg1CSU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "\n",
    "base_model = \"codellama/CodeLlama-7b-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76UlHzhy1CSU"
   },
   "source": [
    "要加载经过微调的 Lora/Qlora 适配器，请使用 PeftModel.from_pretrained。 `output_dir` 应该是包含adapter_config.json和adapter_model.bin的东西："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQrCR0os1CSU"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "model = PeftModel.from_pretrained(model, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roqy_WRi1CSU"
   },
   "source": [
    "尝试与之前相同的提示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrCxouNp1CSU"
   },
   "outputs": [],
   "source": [
    "eval_prompt = \"\"\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
    "\n",
    "You must output the SQL query that answers the question.\n",
    "### Input:\n",
    "Which Class has a Frequency MHz larger than 91.5, and a City of license of hyannis, nebraska?\n",
    "\n",
    "### Context:\n",
    "CREATE TABLE table_name_12 (class VARCHAR, frequency_mhz VARCHAR, city_of_license VARCHAR)\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6IcTOCq1CSU"
   },
   "source": [
    "模型输出：\n",
    "```\n",
    "SELECT class FROM table_name_12 WHERE frequency_mhz > 91.5 AND city_of_license = \"hyannis, nebraska\"\n",
    "```\n",
    "从运行结果可以看到微调是有效果的！也可以将此适配器转换为 Llama.cpp 模型以在本地运行。\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "fileId": "c5b7d095-bdcc-4911-9c1b-a2ffe5f88035",
  "filePath": "/workspace/llm/tester-volume/my_project_v1/llm/实战/预训练/code_llama/frenzyTechAI/fine-tune-code-llama/fine_tune_code_llama.ipynb",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
